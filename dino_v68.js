/**
 * DINO Seminar v6.8 - Master's Class Edition
 * 24 slides, 30 minutes, rigorous mathematical content
 */

const pptxgen = require("pptxgenjs");
const pres = new pptxgen();

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Design System v6.8
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
const C = {
  // Version colors
  v1: "1565C0",      // Blue - DINOv1
  v2: "FF6D00",      // Orange - DINOv2
  v3: "2E7D32",      // Green - DINOv3

  // Semantic colors
  accent: "C62828",  // Red - emphasis, problems
  success: "008000", // Green - solutions, titles

  // Neutrals
  black: "1A1A1A",
  gray: "555555",
  medGray: "888888",
  lightGray: "E0E0E0",
  white: "FFFFFF",

  // Backgrounds
  bg: "FFFFFF",
  cream: "FFF8F0",
  tableAlt: "F5F5F5",
  formulaBg: "F8F8F8",
};

const FONT = "Arial";
const FONT_MONO = "Consolas";
const W = 13.33;
const H = 7.5;
const M = 0.5;
const CW = W - 2 * M;
const MIN_FONT = 24;

// Section definitions
const SECTIONS = [
  { name: "Hook", color: C.black, slides: [1, 2] },
  { name: "DINOv1", color: C.v1, slides: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12] },
  { name: "DINOv2", color: C.v2, slides: [13, 14, 15, 16, 17, 18] },
  { name: "DINOv3", color: C.v3, slides: [19, 20, 21, 22] },
  { name: "Tá»•ng há»£p", color: C.success, slides: [23, 24] },
];

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Presentation Setup
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
pres.defineLayout({ name: "WIDE", width: W, height: H });
pres.layout = "WIDE";
pres.title = "DINO Seminar - Master's Class";
pres.author = "DINO Seminar v6.8";

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Helper Functions
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

function getSectionForSlide(slideNum) {
  for (let i = 0; i < SECTIONS.length; i++) {
    if (SECTIONS[i].slides.includes(slideNum)) {
      return { index: i, section: SECTIONS[i] };
    }
  }
  return { index: 0, section: SECTIONS[0] };
}

function addProgress(slide, slideNum) {
  const y = H - 0.25;
  const totalW = 11;
  const gap = 0.1;
  const barW = (totalW - (SECTIONS.length - 1) * gap) / SECTIONS.length;
  let x = (W - totalW) / 2;

  const { index: activeIdx } = getSectionForSlide(slideNum);

  SECTIONS.forEach((sec, i) => {
    const isActive = i === activeIdx;
    slide.addShape(pres.shapes.RECTANGLE, {
      x, y, w: barW, h: 0.1,
      fill: { color: isActive ? sec.color : C.lightGray },
    });
    x += barW + gap;
  });

  // Slide number
  slide.addText(`${slideNum}/24`, {
    x: W - 1.2, y: H - 0.35, w: 1, h: 0.3,
    fontFace: FONT, fontSize: 11, color: C.medGray, align: "right",
  });
}

function addTitle(slide, title, versionColor = null) {
  slide.addText(title, {
    x: M, y: 0.25, w: CW, h: 0.7,
    fontFace: FONT, fontSize: 32, bold: true,
    color: versionColor || C.success,
  });
}

function addSubtitle(slide, text) {
  slide.addText(text, {
    x: M, y: 0.85, w: CW, h: 0.4,
    fontFace: FONT, fontSize: 18, italic: true, color: C.gray,
  });
}

function addFormula(slide, formula, x, y, w, h, versionColor = C.v1) {
  // Background box
  slide.addShape(pres.shapes.RECTANGLE, {
    x, y, w, h,
    fill: { color: C.formulaBg },
    line: { color: versionColor, dashType: "dash", pt: 1.5 },
  });
  // Formula text
  slide.addText(formula, {
    x: x + 0.15, y: y + 0.1, w: w - 0.3, h: h - 0.2,
    fontFace: FONT_MONO, fontSize: 20, color: C.black,
    valign: "middle",
  });
}

function addBullets(slide, bullets, x, y, w, h, fontSize = MIN_FONT) {
  const textItems = bullets.map(b => ({
    text: b,
    options: { bullet: { type: "bullet" }, breakLine: true }
  }));

  slide.addText(textItems, {
    x, y, w, h,
    fontFace: FONT, fontSize, color: C.black,
    valign: "top", lineSpacingMultiple: 1.3,
  });
}

function addTable(slide, headers, rows, x, y, w, options = {}) {
  const colW = w / headers.length;
  const tableData = [];

  // Header row
  tableData.push(headers.map(h => ({
    text: h,
    options: {
      bold: true, fill: { color: C.success }, color: C.white,
      fontFace: FONT, fontSize: 18, align: "center", valign: "middle",
    }
  })));

  // Data rows
  rows.forEach((row, idx) => {
    tableData.push(row.map((cell, colIdx) => ({
      text: cell,
      options: {
        fill: { color: idx % 2 === 0 ? C.white : C.tableAlt },
        color: C.black,
        fontFace: FONT, fontSize: 16, align: colIdx === 0 ? "left" : "center", valign: "middle",
        bold: colIdx === 0,
      }
    })));
  });

  slide.addTable(tableData, {
    x, y, w, colW: Array(headers.length).fill(colW),
    border: { pt: 0.5, color: C.lightGray },
    ...options,
  });
}

function addPlaceholder(slide, x, y, w, h, label, versionColor = C.v1) {
  slide.addShape(pres.shapes.RECTANGLE, {
    x, y, w, h,
    fill: { color: C.tableAlt },
    line: { color: versionColor, dashType: "dash", pt: 2 },
  });
  slide.addText(`[${label}]`, {
    x, y: y + h / 2 - 0.2, w, h: 0.4,
    fontFace: FONT, fontSize: 14, italic: true, color: C.medGray, align: "center",
  });
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ACT 1: HOOK & PROBLEM (Slides 1-2)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// SLIDE 1: Demo - Attention Maps
(() => {
  const s = pres.addSlide();
  s.background = { color: C.bg };

  addTitle(s, "DINO: Tá»± PhÃ¢n Äoáº¡n KhÃ´ng Cáº§n NhÃ£n");
  addSubtitle(s, "\"Äiá»u nÃ y khÃ´ng nÃªn xáº£y ra Ä‘Æ°á»£c...\"");

  // Image placeholder
  addPlaceholder(s, M, 1.4, 6, 4.5, "Attention maps con cÃ¡: Äáº§u (Ä‘á»), ThÃ¢n (xanh lÃ¡), Ná»n (xanh dÆ°Æ¡ng)", C.v1);

  // Key points
  s.addText([
    { text: "Äiá»u Ká»³ Láº¡:", options: { bold: true, color: C.accent } },
  ], { x: 6.8, y: 1.5, w: 6, h: 0.5, fontFace: FONT, fontSize: 22 });

  addBullets(s, [
    "Head 1: Focus vÃ o Äáº¦U (Ä‘á»)",
    "Head 2: Focus vÃ o THÃ‚N + VÃ‚Y (xanh lÃ¡)",
    "Head 3: Focus vÃ o Ná»€N (xanh dÆ°Æ¡ng)",
    "",
    "Model tá»± Ä‘á»™ng segment váº­t thá»ƒ",
    "NhÆ°ng KHÃ”NG AI dáº¡y nÃ³!",
    "KhÃ´ng cÃ³ nhÃ£n 'Ä‘áº§u', 'vÃ¢y', 'ná»n'",
  ], 6.8, 2.0, 6, 4, 20);

  s.addText("LÃ m sao cÃ³ thá»ƒ?", {
    x: 6.8, y: 5.5, w: 6, h: 0.6,
    fontFace: FONT, fontSize: 24, bold: true, color: C.accent,
  });

  addProgress(s, 1);
  s.addNotes(`NhÃ¬n vÃ o attention maps nÃ y. CÃ¡c heads khÃ¡c nhau tá»± Ä‘á»™ng focus vÃ o pháº§n khÃ¡c nhau: Ä‘áº§u, thÃ¢n, ná»n. Äiá»u nÃ y giá»‘ng nhÆ° model Ä‘Ã£ "há»c" Ä‘Æ°á»£c khÃ¡i niá»‡m "object" vÃ  "background". NhÆ°ng Ä‘Ã¢y lÃ  self-supervised - khÃ´ng ai dáº¡y model Ä‘Ã¢u lÃ  Ä‘áº§u, Ä‘Ã¢u lÃ  vÃ¢y. Model tá»± há»c Ä‘iá»u nÃ y. HÃ´m nay chÃºng ta sáº½ tÃ¬m hiá»ƒu: lÃ m sao Ä‘á»ƒ train má»™t model nhÆ° váº­y?`);
})();

// SLIDE 2: The Goal
(() => {
  const s = pres.addSlide();
  s.background = { color: C.bg };

  addTitle(s, "Má»¥c TiÃªu: Há»c Tá»« áº¢nh KhÃ´ng NhÃ£n");

  // Comparison table
  addTable(s,
    ["", "Supervised", "Má»¥c tiÃªu"],
    [
      ["Dá»¯ liá»‡u", "14M áº£nh cÃ³ nhÃ£n", "HÃ ng tá»· áº£nh khÃ´ng nhÃ£n"],
      ["Chi phÃ­", "$500K + 2 nÄƒm", "$0"],
      ["Kháº£ nÄƒng má»Ÿ rá»™ng", "Bottleneck", "KhÃ´ng giá»›i háº¡n"],
    ],
    M, 1.4, CW * 0.6
  );

  // Key question box
  s.addShape(pres.shapes.RECTANGLE, {
    x: M, y: 4.2, w: CW, h: 1.2,
    fill: { color: C.cream },
    line: { color: C.accent, pt: 2 },
  });
  s.addText("CÃ³ thá»ƒ train model Tá»T NHÆ¯ supervised, nhÆ°ng KHÃ”NG Cáº¦N nhÃ£n?", {
    x: M + 0.3, y: 4.35, w: CW - 0.6, h: 1,
    fontFace: FONT, fontSize: 26, bold: true, color: C.accent, align: "center", valign: "middle",
  });

  // Why it matters
  s.addText("Táº¡i sao quan trá»ng:", {
    x: M, y: 5.6, w: 3, h: 0.4,
    fontFace: FONT, fontSize: 20, bold: true, color: C.black,
  });
  addBullets(s, [
    "áº¢nh khÃ´ng nhÃ£n: VÃ´ háº¡n (internet)",
    "áº¢nh cÃ³ nhÃ£n: Äáº¯t, cháº­m, giá»›i háº¡n",
    "Náº¿u giáº£i Ä‘Æ°á»£c â†’ Scale vÃ´ háº¡n",
  ], M, 5.9, CW, 1.2, 18);

  addProgress(s, 2);
  s.addNotes(`ImageNet: 14 triá»‡u áº£nh, $500K, 2 nÄƒm Ä‘á»ƒ gÃ¡n nhÃ£n. ÄÃ³ lÃ  bottleneck lá»›n nháº¥t cá»§a supervised learning. Trong khi Ä‘Ã³, áº£nh trÃªn internet thÃ¬ vÃ´ háº¡n vÃ  free - nhÆ°ng khÃ´ng cÃ³ nhÃ£n. CÃ¢u há»i: liá»‡u chÃºng ta cÃ³ thá»ƒ train model báº±ng áº£nh khÃ´ng nhÃ£n, mÃ  váº«n Ä‘áº¡t cháº¥t lÆ°á»£ng nhÆ° supervised? ÄÃ¢y lÃ  bÃ i toÃ¡n DINO giáº£i quyáº¿t.`);
})();

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ACT 2: BUILDING DINOv1 (Slides 3-12)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// SLIDE 3: Teacher-Student Framework
(() => {
  const s = pres.addSlide();
  s.background = { color: C.bg };

  addTitle(s, "Ã TÆ°á»Ÿng Äáº§u TiÃªn: MÃ´ HÃ¬nh Teacher-Student", C.v1);

  // Diagram placeholder
  addPlaceholder(s, M, 1.3, 6.5, 4, "SÆ¡ Ä‘á»“ kiáº¿n trÃºc Teacher-Student", C.v1);

  // The intuition
  s.addText("Trá»±c GiÃ¡c:", {
    x: 7.2, y: 1.3, w: 5.5, h: 0.5,
    fontFace: FONT, fontSize: 20, bold: true, color: C.v1,
  });

  s.addText("\"Con ngÆ°á»i nhÃ¬n cÃ¡ tá»« gÃ³c nÃ o cÅ©ng biáº¿t Ä‘Ã³ lÃ  cÃ¡.\nâ†’ Model nÃªn cho CÃ™NG output cho cÃ¡c gÃ³c nhÃ¬n khÃ¡c nhau.\"", {
    x: 7.2, y: 1.8, w: 5.5, h: 1.2,
    fontFace: FONT, fontSize: 18, italic: true, color: C.gray,
  });

  // Design choices
  s.addText("Lá»±a Chá»n Thiáº¿t Káº¿:", {
    x: 7.2, y: 3.2, w: 5.5, h: 0.5,
    fontFace: FONT, fontSize: 20, bold: true, color: C.black,
  });

  addBullets(s, [
    "Táº¡i sao 2 máº¡ng? KhÃ´ng nhÃ£n â†’ tá»± táº¡o \"Ä‘Ã¡p Ã¡n\"",
    "Teacher: Táº¡o pseudo-labels",
    "Student: Há»c predict giá»‘ng Teacher",
    "Loss: Cross-entropy (chi tiáº¿t sau)",
  ], 7.2, 3.6, 5.5, 2.5, 18);

  // Warning
  s.addText("âš  NhÆ°ng khoan... CÃ³ váº¥n Ä‘á»!", {
    x: 7.2, y: 5.8, w: 5.5, h: 0.5,
    fontFace: FONT, fontSize: 20, bold: true, color: C.accent,
  });

  addProgress(s, 3);
  s.addNotes(`Ã tÆ°á»Ÿng Ä‘áº§u tiÃªn: DÃ¹ng 2 networks - Teacher vÃ  Student. Tá»« 1 áº£nh, táº¡o 2 views khÃ¡c nhau (crop, color jitter...). Teacher xá»­ lÃ½ view 1, Student xá»­ lÃ½ view 2. Má»¥c tiÃªu: Student pháº£i predict giá»‘ng Teacher. Intuition: Náº¿u 2 views tá»« cÃ¹ng 1 áº£nh, chÃºng nÃªn cÃ³ cÃ¹ng representation. Nghe há»£p lÃ½! NhÆ°ng cÃ³ má»™t váº¥n Ä‘á» nghiÃªm trá»ng...`);
})();

// SLIDE 4: Network Architecture
(() => {
  const s = pres.addSlide();
  s.background = { color: C.bg };

  addTitle(s, "Kiáº¿n TrÃºc Máº¡ng", C.v1);

  // Architecture formula
  addFormula(s, "g = h âˆ˜ f\n\nf = ViT Backbone (output cho downstream)\nh = Projection Head (chá»‰ khi training)", M, 1.3, 6, 1.8, C.v1);

  // Projection head details
  s.addText("Thiáº¿t Káº¿ Projection Head:", {
    x: M, y: 3.4, w: 6, h: 0.4,
    fontFace: FONT, fontSize: 20, bold: true, color: C.v1,
  });

  addTable(s,
    ["Lá»›p", "Chiá»u", "Ghi chÃº"],
    [
      ["Input", "d (ViT output)", "VD: 768 cho ViT-B"],
      ["Hidden 1", "2048", "+ GELU"],
      ["Hidden 2", "2048", "+ GELU"],
      ["Output", "K = 65,536", "Weight normalized"],
    ],
    M, 3.8, 6
  );

  // Key design decisions
  s.addText("Quyáº¿t Äá»‹nh Thiáº¿t Káº¿ Quan Trá»ng:", {
    x: 7, y: 1.3, w: 5.8, h: 0.4,
    fontFace: FONT, fontSize: 20, bold: true, color: C.black,
  });

  addBullets(s, [
    "KhÃ´ng cÃ³ predictor (khÃ¡c BYOL)",
    "Student = Teacher architecture",
    "KhÃ´ng Batch Normalization trong ViT",
    "â†’ ToÃ n há»‡ thá»‘ng BN-free!",
  ], 7, 1.7, 5.8, 2, 18);

  // Why BN-free
  s.addShape(pres.shapes.RECTANGLE, {
    x: 7, y: 4, w: 5.8, h: 1.5,
    fill: { color: C.cream },
  });
  s.addText("Táº¡i sao BN-free quan trá»ng:\nBN táº¡o dependencies ngáº§m trÃªn batch.\nSSL hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n khi khÃ´ng cÃ³ BN.", {
    x: 7.2, y: 4.1, w: 5.4, h: 1.4,
    fontFace: FONT, fontSize: 16, color: C.gray,
  });

  addProgress(s, 4);
  s.addNotes(`Network g gá»“m backbone f vÃ  projection head h. Backbone lÃ  ViT - dÃ¹ng cho downstream tasks. Projection head lÃ  3-layer MLP vá»›i hidden dim 2048, output K=65536. KhÃ´ng cÃ³ predictor nhÆ° BYOL - Student vÃ  Teacher cÃ¹ng architecture. Quan trá»ng: toÃ n bá»™ system khÃ´ng dÃ¹ng batch normalization. Äiá»u nÃ y quan trá»ng vÃ¬ BN táº¡o dependencies ngáº§m trÃªn batch statistics.`);
})();

// SLIDE 5: Loss Function
(() => {
  const s = pres.addSlide();
  s.background = { color: C.bg };

  addTitle(s, "HÃ m Loss - PhÃ¢n TÃ­ch Chi Tiáº¿t", C.v1);

  // Main loss formula
  s.addText("Cross-Entropy Loss:", {
    x: M, y: 1.2, w: CW, h: 0.4,
    fontFace: FONT, fontSize: 20, bold: true, color: C.v1,
  });

  addFormula(s, "L = -Î£â‚– Pâ‚œ(x)[k] Â· log Pâ‚›(x')[k]", M, 1.6, CW, 0.8, C.v1);

  // Student probability
  s.addText("XÃ¡c Suáº¥t Student (softmax chuáº©n):", {
    x: M, y: 2.6, w: 6, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.black,
  });
  addFormula(s, "Pâ‚›(x)[k] = exp(gÎ¸â‚›(x)[k] / Ï„â‚›) / Î£â‚–' exp(gÎ¸â‚›(x)[k'] / Ï„â‚›)\n\nÏ„â‚› = 0.1 (nhiá»‡t Ä‘á»™ student)", M, 3.0, 6.2, 1.3, C.v1);

  // Teacher probability
  s.addText("XÃ¡c Suáº¥t Teacher (cÃ³ centering):", {
    x: 6.8, y: 2.6, w: 6, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.black,
  });
  addFormula(s, "Pâ‚œ(x)[k] = exp((gÎ¸â‚œ(x)[k] - c[k]) / Ï„â‚œ) / Î£â‚–' exp(...)\n\nÏ„â‚œ = 0.04 (nhiá»‡t Ä‘á»™ teacher)\nc = vector centering", 6.8, 3.0, 6, 1.5, C.v1);

  // Why cross-entropy
  s.addText("Táº¡i Sao Cross-Entropy?", {
    x: M, y: 4.8, w: CW, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.black,
  });
  addBullets(s, [
    "Äo divergence giá»¯a hai phÃ¢n phá»‘i",
    "Minimize â†’ Student tiá»‡m cáº­n phÃ¢n phá»‘i Teacher",
    "Báº¥t Ä‘á»‘i xá»©ng: Teacher lÃ  \"target\", Student lÃ  \"prediction\"",
  ], M, 5.2, CW, 1.5, 18);

  addProgress(s, 5);
  s.addNotes(`Loss lÃ  cross-entropy giá»¯a Teacher vÃ  Student outputs. Student dÃ¹ng softmax chuáº©n vá»›i temperature Ï„_s = 0.1. Teacher dÃ¹ng softmax vá»›i centering (trá»« c) vÃ  temperature Ï„_t = 0.04. Táº¡i sao temperatures khÃ¡c nhau? Slide 9 sáº½ giáº£i thÃ­ch. Táº¡i sao centering? Slide 8. K=65536 output cÃ³ thá»ƒ hiá»ƒu nhÆ° soft assignment cho K prototypes - tÆ°Æ¡ng tá»± clustering nhÆ°ng differentiable.`);
})();

// SLIDE 6: Collapse Problem
(() => {
  const s = pres.addSlide();
  s.background = { color: C.bg };

  addTitle(s, "Váº¥n Äá» Sá»¥p Äá»• (Collapse)", C.accent);

  // Diagram placeholder
  addPlaceholder(s, M, 1.3, CW, 3.2, "Mode Collapse (táº¥t cáº£ Ä‘iá»ƒm tá»¥ 1 chá»—) vs Uniform Collapse (lÆ°á»›i Ä‘á»u)", C.accent);

  // Explanation table
  addTable(s,
    ["Loáº¡i Collapse", "NguyÃªn nhÃ¢n", "Káº¿t quáº£"],
    [
      ["Mode Collapse", "Teacher & Student output cÃ¹ng giÃ¡ trá»‹", "Loss = 0, nhÆ°ng vÃ´ nghÄ©a"],
      ["Uniform Collapse", "Output tráº£i Ä‘á»u", "Loss tháº¥p, nhÆ°ng vÃ´ dá»¥ng"],
    ],
    M, 4.7, CW * 0.7
  );

  // The dilemma
  s.addText("TÃ¬nh Huá»‘ng KhÃ³:", {
    x: 9, y: 4.7, w: 3.8, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.accent,
  });
  s.addText("KhÃ´ng nhÃ£n â†’ KhÃ´ng gÃ¬ ngÄƒn Teacher output háº±ng sá»‘.\n\nCÃ¡ch DINO: KhÃ´ng cáº§n negatives!", {
    x: 9, y: 5.1, w: 3.8, h: 1.5,
    fontFace: FONT, fontSize: 16, color: C.gray,
  });

  addProgress(s, 6);
  s.addNotes(`ÄÃ¢y lÃ  váº¥n Ä‘á» lá»›n nháº¥t cá»§a self-supervised: collapse. Mode collapse: Teacher vÃ  Student "thÃ´ng Ä‘á»“ng" - cáº£ 2 output cÃ¹ng 1 vector cho Má»ŒI áº£nh. Loss = 0, nhÆ°ng model khÃ´ng há»c Ä‘Æ°á»£c gÃ¬. Uniform collapse: Output tráº£i Ä‘á»u nhÆ° uniform distribution - cÅ©ng vÃ´ nghÄ©a. Contrastive learning giáº£i quyáº¿t báº±ng negative samples. DINO cÃ³ cÃ¡ch khÃ¡c: khÃ´ng cáº§n negatives. 3 tricks sau Ä‘Ã¢y.`);
})();

// SLIDE 7: EMA Teacher
(() => {
  const s = pres.addSlide();
  s.background = { color: C.bg };

  addTitle(s, "EMA Teacher - CÆ¡ Cháº¿ Äáº§y Äá»§", C.v1);

  // Main formula
  addFormula(s, "Î¸â‚œ â† Î»Â·Î¸â‚œ + (1-Î»)Â·Î¸â‚›\n\nÎ»: cosine schedule 0.996 â†’ 1.0 trong quÃ¡ trÃ¬nh training", M, 1.3, 7, 1.4, C.v1);

  // Explanation
  s.addText("Ã nghÄ©a:", {
    x: M, y: 3.0, w: 6.5, h: 0.4,
    fontFace: FONT, fontSize: 20, bold: true, color: C.black,
  });
  addBullets(s, [
    "Teacher giá»¯ 99.6% weights cÅ©",
    "Chá»‰ láº¥y 0.4% tá»« Student má»—i bÆ°á»›c",
    "Î» tÄƒng dáº§n (Teacher cÃ ng \"Ä‘Ã³ng bÄƒng\")",
  ], M, 3.4, 6.5, 1.8, 18);

  // Why it works
  s.addText("Táº¡i Sao EMA Hoáº¡t Äá»™ng:", {
    x: 8, y: 1.3, w: 4.8, h: 0.4,
    fontFace: FONT, fontSize: 20, bold: true, color: C.v1,
  });

  addTable(s,
    ["Insight", "Giáº£i thÃ­ch"],
    [
      ["Polyak-Ruppert", "Model ensembling vá»›i decay"],
      ["Teacher > Student", "Targets cháº¥t lÆ°á»£ng cao hÆ¡n"],
      ["Targets á»•n Ä‘á»‹nh", "Di chuyá»ƒn cháº­m = tÃ­n hiá»‡u á»•n Ä‘á»‹nh"],
      ["KhÃ´ng \"thÃ´ng Ä‘á»“ng\"", "Tá»‘c Ä‘á»™ update khÃ¡c nhau"],
    ],
    8, 1.8, 4.8
  );

  // Key observation
  s.addShape(pres.shapes.RECTANGLE, {
    x: M, y: 5.3, w: CW, h: 1,
    fill: { color: C.cream },
  });
  s.addText("Quan sÃ¡t quan trá»ng: \"Teacher cÃ³ performance tá»‘t hÆ¡n Student suá»‘t quÃ¡ trÃ¬nh training, do Ä‘Ã³ hÆ°á»›ng dáº«n training báº±ng cÃ¡ch cung cáº¥p target features cháº¥t lÆ°á»£ng cao hÆ¡n.\"", {
    x: M + 0.2, y: 5.4, w: CW - 0.4, h: 0.9,
    fontFace: FONT, fontSize: 16, italic: true, color: C.gray, valign: "middle",
  });

  addProgress(s, 7);
  s.addNotes(`EMA Teacher lÃ  critical. Update rule: Teacher giá»¯ 99.6% weights cÅ© vÃ  láº¥y 0.4% tá»« Student. Î» theo cosine schedule tá»« 0.996 lÃªn 1.0. Táº¡i sao hoáº¡t Ä‘á»™ng? ÄÃ¢y lÃ  Polyak-Ruppert averaging - model ensembling vá»›i decay. Teacher performs better than Student throughout training - cung cáº¥p targets cháº¥t lÆ°á»£ng cao hÆ¡n. Náº¿u Teacher vÃ  Student update cÃ¹ng tá»‘c Ä‘á»™, chÃºng sáº½ "Ä‘á»“ng lÃµa" collapse.`);
})();

// SLIDE 8: Centering
(() => {
  const s = pres.addSlide();
  s.background = { color: C.bg };

  addTitle(s, "Centering - CÃ´ng Thá»©c Chi Tiáº¿t", C.v1);

  // Formula
  addFormula(s, "c â† mÂ·c + (1-m) Â· (1/B) Â· Î£áµ¢ gÎ¸â‚œ(xáµ¢)\n\nm = tham sá»‘ tá»‘c Ä‘á»™ (VD: 0.9)\nB = batch size", M, 1.3, 7, 1.6, C.v1);

  // How applied
  s.addText("CÃ¡ch Ãp Dá»¥ng Centering:", {
    x: M, y: 3.2, w: 6.5, h: 0.4,
    fontFace: FONT, fontSize: 20, bold: true, color: C.black,
  });
  addFormula(s, "gâ‚œ(x) â† gâ‚œ(x) - c\n\nTrá»« center trÆ°á»›c softmax", M, 3.6, 5, 1, C.v1);

  // Why it prevents collapse
  s.addText("Táº¡i Sao Centering NgÄƒn Mode Collapse:", {
    x: M, y: 5.0, w: 6, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.v1,
  });

  addTable(s,
    ["TÃ¬nh huá»‘ng", "Sau Centering"],
    [
      ["Teacher output háº±ng sá»‘ v", "c â†’ v, thÃ¬ v - c = 0"],
      ["Buá»™c output Ä‘a dáº¡ng!", "KhÃ´ng thá»ƒ collapse vá» háº±ng sá»‘"],
    ],
    M, 5.4, 6
  );

  // Side effect warning
  s.addShape(pres.shapes.RECTANGLE, {
    x: 7.5, y: 1.3, w: 5.3, h: 2,
    fill: { color: "FFF0F0" },
    line: { color: C.accent, pt: 1 },
  });
  s.addText("âš  TÃ¡c Dá»¥ng Phá»¥:\n\nCentering Ä‘Æ¡n láº» khuyáº¿n khÃ­ch UNIFORM collapse!\n\nâ†’ Cáº§n sharpening Ä‘á»ƒ cÃ¢n báº±ng", {
    x: 7.7, y: 1.4, w: 5, h: 1.9,
    fontFace: FONT, fontSize: 16, color: C.accent,
  });

  // Key insight
  s.addText("Quan trá»ng: Chá»‰ dÃ¹ng first-order batch stats â†’ hoáº¡t Ä‘á»™ng vá»›i má»i batch size", {
    x: 7.5, y: 4, w: 5.3, h: 0.8,
    fontFace: FONT, fontSize: 16, italic: true, color: C.gray,
  });

  addProgress(s, 8);
  s.addNotes(`Centering ngÄƒn mode collapse. Center c lÃ  EMA cá»§a Teacher outputs trÃªn batches. Trá»« c tá»« Teacher output trÆ°á»›c softmax. Náº¿u Teacher collapse vÃ  output constant v cho Má»ŒI áº£nh, thÃ¬ batch mean = v, c há»™i tá»¥ vá» v. Sau centering: v - c = 0. BUá»˜C Teacher pháº£i output khÃ¡c nhau. Centering chá»‰ dÃ¹ng first-order statistics, hoáº¡t Ä‘á»™ng tá»‘t vá»›i nhiá»u batch sizes. NhÆ°ng centering cÃ³ side effect: khuyáº¿n khÃ­ch uniform collapse. Cáº§n sharpening Ä‘á»ƒ balance.`);
})();

// SLIDE 9: Sharpening
(() => {
  const s = pres.addSlide();
  s.background = { color: C.bg };

  addTitle(s, "Sharpening - PhÃ¢n TÃ­ch Temperature", C.v1);

  // Temperature effect placeholder
  addPlaceholder(s, M, 1.3, 6, 3, "Hiá»‡u á»©ng temperature: Ï„=1.0 (pháº³ng) â†’ Ï„=0.04 (nhá»n)", C.v1);

  // Formula
  s.addText("Temperature trong Softmax:", {
    x: 7, y: 1.3, w: 5.8, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.black,
  });
  addFormula(s, "P[k] = exp(z[k]/Ï„) / Î£â‚–' exp(z[k']/Ï„)\n\nÏ„ â†’ 0: one-hot (argmax)\nÏ„ â†’ âˆ: uniform", 7, 1.7, 5.8, 1.6, C.v1);

  // DINO's choice
  s.addText("Lá»±a Chá»n Temperature cá»§a DINO:", {
    x: 7, y: 3.6, w: 5.8, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.v1,
  });

  addTable(s,
    ["Máº¡ng", "Ï„", "Hiá»‡u á»©ng"],
    [
      ["Teacher", "0.04", "Sharp/tá»± tin"],
      ["Student", "0.1", "Má»m hÆ¡n (dá»… há»c)"],
    ],
    7, 4.0, 5.8
  );

  // Balance explanation
  s.addShape(pres.shapes.RECTANGLE, {
    x: M, y: 4.8, w: CW, h: 1.5,
    fill: { color: C.cream },
  });
  s.addText("CÃ¢n Báº±ng Centering + Sharpening:", {
    x: M + 0.2, y: 4.9, w: CW - 0.4, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.success,
  });
  s.addText("â€¢ Centering Ä‘Æ¡n láº» â†’ khuyáº¿n khÃ­ch UNIFORM collapse\nâ€¢ Sharpening Ä‘Æ¡n láº» â†’ khuyáº¿n khÃ­ch output NHá»ŒN\nâ€¢ Káº¿t há»£p â†’ CÃ‚N Báº°NG, training á»•n Ä‘á»‹nh!", {
    x: M + 0.2, y: 5.3, w: CW - 0.4, h: 1,
    fontFace: FONT, fontSize: 16, color: C.black,
  });

  addProgress(s, 9);
  s.addNotes(`Temperature kiá»ƒm soÃ¡t Ä‘á»™ "nhá»n" cá»§a softmax. Ï„ tháº¥p (0.04 cho Teacher) = sharp, confident output. Ï„ cao = soft, uncertain. Táº¡i sao khÃ¡c nhau? Teacher dÃ¹ng Ï„=0.04 (ráº¥t sharp) Ä‘á»ƒ ngÄƒn uniform collapse. Student dÃ¹ng Ï„=0.1 (softer) vÃ¬ há»c tá»« targets quÃ¡ sharp khÃ³ hÆ¡n. Key insight: Centering khuyáº¿n khÃ­ch uniform, Sharpening khuyáº¿n khÃ­ch peaked. CÃ¹ng nhau chÃºng balance, táº¡o stable training.`);
})();

// SLIDE 10: Ablation
(() => {
  const s = pres.addSlide();
  s.background = { color: C.bg };

  addTitle(s, "Ablation: Bá» Tá»«ng ThÃ nh Pháº§n ThÃ¬ Sao?", C.v1);

  // Ablation table
  addTable(s,
    ["Cáº¥u hÃ¬nh", "Káº¿t quáº£"],
    [
      ["DINO Ä‘áº§y Ä‘á»§ (EMA + Centering + Sharpening)", "âœ“ Hoáº¡t Ä‘á»™ng (80.1% ImageNet)"],
      ["Bá» EMA (copy weights)", "âœ— KhÃ´ng há»™i tá»¥"],
      ["Bá» Centering", "âœ— Mode collapse"],
      ["Bá» Sharpening (Ï„_t = Ï„_s = 0.1)", "âœ— Uniform collapse"],
      ["Bá» cáº£ Centering vÃ  Sharpening", "âœ— Collapse ngay láº­p tá»©c"],
    ],
    M, 1.3, CW * 0.75
  );

  // Three pillars diagram placeholder
  addPlaceholder(s, 9.5, 1.3, 3.3, 2.5, "Ba trá»¥ cá»™t há»— trá»£ Training á»•n Ä‘á»‹nh", C.v1);

  // Key finding quote
  s.addShape(pres.shapes.RECTANGLE, {
    x: M, y: 4.6, w: CW, h: 1.2,
    fill: { color: C.cream },
  });
  s.addText("\"Centering ngÄƒn má»™t dimension chiáº¿m Æ°u tháº¿ nhÆ°ng khuyáº¿n khÃ­ch collapse vá» uniform distribution, trong khi sharpening cÃ³ hiá»‡u á»©ng ngÆ°á»£c láº¡i. Ãp dá»¥ng cáº£ hai cÃ¢n báº±ng hiá»‡u á»©ng cá»§a nhau.\"", {
    x: M + 0.2, y: 4.7, w: CW - 0.4, h: 1.1,
    fontFace: FONT, fontSize: 16, italic: true, color: C.gray, valign: "middle",
  });

  // Summary
  s.addText("Cáº£ BA Ä‘á»u cáº§n thiáº¿t. Bá» báº¥t ká»³ â†’ collapse.", {
    x: M, y: 6.0, w: CW, h: 0.5,
    fontFace: FONT, fontSize: 22, bold: true, color: C.accent, align: "center",
  });

  addProgress(s, 10);
  s.addNotes(`Ablation study chá»©ng minh má»—i component lÃ  essential. Bá» EMA â†’ fails to converge vÃ¬ Teacher vÃ  Student update cÃ¹ng nhau collapse. Bá» centering â†’ mode collapse. Bá» sharpening â†’ uniform collapse. Paper nÃ³i rÃµ: "centering ngÄƒn 1 dimension dominate nhÆ°ng khuyáº¿n khÃ­ch uniform collapse, sharpening cÃ³ hiá»‡u á»©ng ngÆ°á»£c láº¡i." KhÃ´ng pháº£i optional tricks - Ä‘Ã¢y lÃ  core cá»§a DINO.`);
})();

// SLIDE 11: Multi-crop
(() => {
  const s = pres.addSlide();
  s.background = { color: C.bg };

  addTitle(s, "Chiáº¿n LÆ°á»£c Multi-Crop: Local-to-Global", C.v1);

  // Diagram placeholder
  addPlaceholder(s, M, 1.3, 6.5, 4, "Multi-crop: 2 global (224Â²) + 6 local (96Â²)", C.v1);

  // The insight
  s.addText("Insight Quan Trá»ng:", {
    x: 7.2, y: 1.3, w: 5.6, h: 0.4,
    fontFace: FONT, fontSize: 20, bold: true, color: C.v1,
  });
  s.addText("\"Tháº¥y VÃ‚Y CÃ (local)\nâ†’ pháº£i biáº¿t Ä‘Ã³ lÃ  CON CÃ (global)\"", {
    x: 7.2, y: 1.7, w: 5.6, h: 0.8,
    fontFace: FONT, fontSize: 20, italic: true, color: C.accent,
  });

  // Table
  addTable(s,
    ["Loáº¡i Crop", "KÃ­ch thÆ°á»›c", "Äá»™ phá»§", "â†’"],
    [
      ["Global 1-2", "224Ã—224", ">50%", "Teacher"],
      ["Local 1-6", "96Ã—96", "<50%", "Student"],
    ],
    7.2, 2.8, 5.6
  );

  // Effect
  s.addText("Táº¡i Sao Buá»™c Hiá»ƒu Ngá»¯ NghÄ©a:", {
    x: 7.2, y: 4.2, w: 5.6, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.black,
  });
  s.addText("Student chá»‰ tháº¥y cÃ¡nh â†’ pháº£i predict \"Ä‘Ã¢y lÃ  con chim\"\n\nâ†’ Pháº£i há»c KHÃI NIá»†M NGá»® NGHÄ¨A, khÃ´ng chá»‰ copy pixels!", {
    x: 7.2, y: 4.6, w: 5.6, h: 1.2,
    fontFace: FONT, fontSize: 16, color: C.gray,
  });

  // Compute cost
  s.addText("TÃ­nh toÃ¡n: ~2.4Ã— chi phÃ­, nhÆ°ng cho phÃ©p hiá»ƒu ngá»¯ nghÄ©a", {
    x: M, y: 5.8, w: CW, h: 0.4,
    fontFace: FONT, fontSize: 16, italic: true, color: C.medGray,
  });

  addProgress(s, 11);
  s.addNotes(`ÄÃ¢y lÃ  insight quan trá»ng nháº¥t cá»§a DINO. Teacher nhÃ¬n global (>50% áº£nh), Student nhÃ¬n local (<50% áº£nh). Student pháº£i predict output cá»§a Teacher. VÃ­ dá»¥: Student chá»‰ tháº¥y vÃ¢y cÃ¡, nhÆ°ng pháº£i output giá»‘ng Teacher (tháº¥y cáº£ con cÃ¡). Äiá»u nÃ y BUá»˜C Student hiá»ƒu: "vÃ¢y nÃ y thuá»™c vá» con cÃ¡". ÄÃ¢y lÃ  lÃ½ do DINO há»c Ä‘Æ°á»£c semantic concepts mÃ  khÃ´ng cáº§n labels.`);
})();

// SLIDE 12: DINOv1 Results
(() => {
  const s = pres.addSlide();
  s.background = { color: C.bg };

  addTitle(s, "Káº¿t Quáº£ DINOv1", C.v1);

  // Results table
  addTable(s,
    ["PhÆ°Æ¡ng phÃ¡p", "ImageNet Acc", "NhÃ£n", "NÄƒm"],
    [
      ["DINO v1", "80.1%", "0", "2021"],
      ["Supervised ViT", "76.5%", "14M", "-"],
      ["SimCLR", "69.3%", "0", "2020"],
      ["BYOL", "74.3%", "0", "2020"],
      ["MoCo v3", "76.7%", "0", "2021"],
    ],
    M, 1.3, 7
  );

  // Milestone
  s.addShape(pres.shapes.RECTANGLE, {
    x: M, y: 4.0, w: 7, h: 0.8,
    fill: { color: "E8F5E9" },
    line: { color: C.success, pt: 2 },
  });
  s.addText("ğŸ¯ Láº§n Ä‘áº§u SSL VÆ¯á»¢T Supervised trÃªn ImageNet!", {
    x: M + 0.2, y: 4.1, w: 6.6, h: 0.7,
    fontFace: FONT, fontSize: 20, bold: true, color: C.success, valign: "middle",
  });

  // Limitations
  s.addText("NhÆ°ng... CÃ²n Háº¡n Cháº¿:", {
    x: 8, y: 1.3, w: 4.8, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.accent,
  });

  addTable(s,
    ["Háº¡n cháº¿", "áº¢nh hÆ°á»Ÿng"],
    [
      ["Data nhá» (1.28M)", "Äa dáº¡ng háº¡n cháº¿"],
      ["Chá»‰ classification", "Dense tasks?"],
      ["Má»™t loss (CLS)", "Patch-level?"],
    ],
    8, 1.8, 4.8
  );

  // Questions for v2
  s.addText("CÃ¢u há»i cho v2:", {
    x: 8, y: 4.0, w: 4.8, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.v2,
  });
  addBullets(s, [
    "Nhiá»u data hÆ¡n = tá»‘t hÆ¡n?",
    "Dense tasks cáº§n gÃ¬?",
    "CÃ³ thá»ƒ xÃ¢y Foundation Model?",
  ], 8, 4.4, 4.8, 2, 16);

  addProgress(s, 12);
  s.addNotes(`DINOv1 Ä‘áº¡t milestone quan trá»ng: 80.1% ImageNet vá»›i 0 labels - láº§n Ä‘áº§u SSL vÆ°á»£t supervised! Emerging properties: attention heads tá»± Ä‘á»™ng segment objects. NhÆ°ng cÃ²n háº¡n cháº¿: chá»‰ train trÃªn ImageNet (1.28M áº£nh), chá»‰ lÃ m tá»‘t classification, dÃ¹ng 1 loss (CLS token). CÃ¢u há»i cho v2: Nhiá»u data hÆ¡n cÃ³ tá»‘t hÆ¡n? Dense tasks cáº§n gÃ¬ thÃªm? CÃ³ thá»ƒ táº¡o Foundation Model khÃ´ng?`);
})();

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ACT 3: EVOLUTION TO v2 (Slides 13-18)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// SLIDE 13: v1 Limitations
(() => {
  const s = pres.addSlide();
  s.background = { color: C.bg };

  addTitle(s, "Háº¡n Cháº¿ v1 â†’ CÃ¢u Há»i v2", C.v2);

  addTable(s,
    ["KhÃ­a cáº¡nh", "v1 Hiá»‡n táº¡i", "CÃ¢u há»i cho v2"],
    [
      ["Dá»¯ liá»‡u", "1.28M (ImageNet)", "Nhiá»u data hÆ¡n cÃ³ tá»‘t? CÃ¡ch curate?"],
      ["Tasks", "Chá»‰ Classification", "CÃ³ thá»ƒ segmentation, depth?"],
      ["Loss", "Chá»‰ CLS token", "CÃ³ thá»ƒ há»c patch-level features?"],
      ["Scale", "ViT-B/S", "CÃ³ thá»ƒ scale lÃªn 1B+ params?"],
    ],
    M, 1.3, CW
  );

  // Foundation Model definition
  s.addShape(pres.shapes.RECTANGLE, {
    x: M, y: 4.0, w: CW, h: 1.2,
    fill: { color: C.cream },
    line: { color: C.v2, pt: 2 },
  });
  s.addText("Äá»‹nh nghÄ©a Foundation Model:", {
    x: M + 0.2, y: 4.1, w: CW - 0.4, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.v2,
  });
  s.addText("\"1 backbone pretrained â†’ nhiá»u tasks â†’ frozen features + simple head\"", {
    x: M + 0.2, y: 4.5, w: CW - 0.4, h: 0.6,
    fontFace: FONT, fontSize: 20, italic: true, color: C.black,
  });

  // Three innovations preview
  s.addText("Ba Äá»•i Má»›i cá»§a v2:", {
    x: M, y: 5.5, w: CW, h: 0.4,
    fontFace: FONT, fontSize: 20, bold: true, color: C.v2,
  });
  s.addText("1. Data Curation (LVD-142M)    2. Ba Losses (DINO + iBOT + KoLeo)    3. Scale (ViT-g 1.1B)", {
    x: M, y: 5.9, w: CW, h: 0.5,
    fontFace: FONT, fontSize: 18, color: C.gray,
  });

  addProgress(s, 13);
  s.addNotes(`DINOv1 groundbreaking nhÆ°ng limited. Chá»‰ train trÃªn ImageNet - náº¿u cÃ³ billions images thÃ¬ sao? Chá»‰ classification - segmentation, depth estimation? Chá»‰ CLS token - patches? v2 asks: CÃ³ thá»ƒ táº¡o Foundation Model khÃ´ng? Má»™t backbone cho má»i thá»© - classification, segmentation, depth, retrieval - khÃ´ng cáº§n task-specific training.`);
})();

// SLIDE 14: Data Curation
(() => {
  const s = pres.addSlide();
  s.background = { color: C.bg };

  addTitle(s, "Quy TrÃ¬nh Xá»­ LÃ½ Dá»¯ Liá»‡u - LVD-142M", C.v2);

  // Pipeline placeholder
  addPlaceholder(s, M, 1.3, 5.5, 4.5, "Phá»…u lá»c: 1.2B â†’ 1.1B â†’ 744M â†’ 142M curated", C.v2);

  // Pipeline steps
  s.addText("CÃ¡c BÆ°á»›c Xá»­ LÃ½:", {
    x: 6.2, y: 1.3, w: 6.6, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.v2,
  });

  const steps = [
    "1.2B raw (thu tháº­p web)",
    "â†’ Lá»c an toÃ n (NSFW, bá»‹ cáº¥m)",
    "â†’ Loáº¡i trÃ¹ng PCA hash",
    "1.1B",
    "â†’ Copy-detection (sim > 0.6, k=64)",
    "744M",
    "â†’ Loáº¡i rÃ² rá»‰ benchmark (sim > 0.45)",
    "â†’ SSL retrieval (k-means 100k)",
    "142M Ä‘Ã£ curate",
  ];

  s.addText(steps.join("\n"), {
    x: 6.2, y: 1.7, w: 6.6, h: 3,
    fontFace: FONT_MONO, fontSize: 14, color: C.black,
  });

  // Implementation note
  s.addText("Triá»ƒn khai: Faiss (GPU), 20Ã—8 V100, <2 ngÃ y", {
    x: 6.2, y: 4.8, w: 6.6, h: 0.4,
    fontFace: FONT, fontSize: 14, italic: true, color: C.medGray,
  });

  // Key finding
  s.addShape(pres.shapes.RECTANGLE, {
    x: M, y: 5.8, w: CW, h: 0.7,
    fill: { color: "FFF3E0" },
    line: { color: C.v2, pt: 2 },
  });
  s.addText("PhÃ¡t hiá»‡n quan trá»ng: 142M curated > 1.2B uncurated trÃªn Má»ŒI benchmark!", {
    x: M + 0.2, y: 5.9, w: CW - 0.4, h: 0.6,
    fontFace: FONT, fontSize: 20, bold: true, color: C.v2, valign: "middle",
  });

  addProgress(s, 14);
  s.addNotes(`Data curation lÃ  critical cho v2. Tá»« 1.2B raw web images, filter xuá»‘ng 142M qua nhiá»u stages. Safety filtering, deduplication báº±ng PCA hashes, copy-detection vá»›i k=64 neighbors, loáº¡i bá» images quÃ¡ giá»‘ng evaluation benchmarks, cuá»‘i cÃ¹ng retrieval báº±ng ViT-H embeddings. Ablation quan trá»ng: 142M curated beats 1.2B uncurated trÃªn má»i benchmark. Quality > quantity.`);
})();

// SLIDE 15: iBOT Loss
(() => {
  const s = pres.addSlide();
  s.background = { color: C.bg };

  addTitle(s, "iBOT Loss - Dá»± ÄoÃ¡n Masked Patch", C.v2);

  // Diagram placeholder
  addPlaceholder(s, M, 1.3, 6, 3, "Student (masked) vs Teacher (Ä‘áº§y Ä‘á»§) â†’ predict semantic tokens", C.v2);

  // Formula
  s.addText("CÃ´ng Thá»©c iBOT Loss:", {
    x: 7, y: 1.3, w: 5.8, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.v2,
  });
  addFormula(s, "L_iBOT = -Î£áµ¢ pâ‚œáµ¢ Â· log(pâ‚›áµ¢)\n\ni = chá»‰ sá»‘ masked patch\npâ‚œ = teacher (Sinkhorn-Knopp)\npâ‚› = student (softmax)", 7, 1.7, 5.8, 1.8, C.v2);

  // Comparison table
  s.addText("iBOT vs MAE:", {
    x: M, y: 4.6, w: CW, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.black,
  });

  addTable(s,
    ["KhÃ­a cáº¡nh", "MAE", "iBOT"],
    [
      ["Target", "GiÃ¡ trá»‹ pixel", "Semantic tokens tá»« Teacher"],
      ["Loss", "MSE reconstruction", "Cross-entropy"],
      ["Features", "Cáº§n finetuning", "Hoáº¡t Ä‘á»™ng FROZEN"],
    ],
    M, 5.0, CW * 0.7
  );

  // Key note
  s.addText("á» scale lá»›n: UNTIED heads tá»‘t hÆ¡n (tÃ¡ch riÃªng DINO vÃ  iBOT heads)", {
    x: 9, y: 5.5, w: 4, h: 0.6,
    fontFace: FONT, fontSize: 14, italic: true, color: C.medGray,
  });

  addProgress(s, 15);
  s.addNotes(`iBOT thÃªm patch-level learning. Student nháº­n masked patches, Teacher nháº­n full image. Student predict Teacher's output táº¡i masked positions. Quan trá»ng: iBOT predict semantic tokens, khÃ´ng pháº£i pixels nhÆ° MAE. MAE reconstruct raw pixels - há»c texture vÃ  low-level patterns. iBOT predict representation cá»§a Teacher - há»c semantic meaning. Káº¿t quáº£: frozen iBOT features work gáº§n nhÆ° finetuned MAE trÃªn segmentation.`);
})();

// SLIDE 16: KoLeo Loss
(() => {
  const s = pres.addSlide();
  s.background = { color: C.bg };

  addTitle(s, "KoLeo Loss - Embeddings Äá»u", C.v2);

  // Diagram placeholder
  addPlaceholder(s, M, 1.3, 5.5, 3, "KhÃ´ng cÃ³ KoLeo (tá»¥ cá»¥m) vs CÃ³ KoLeo (tráº£i Ä‘á»u)", C.v2);

  // Formula
  s.addText("CÃ´ng Thá»©c KoLeo Loss:", {
    x: 6.5, y: 1.3, w: 6.3, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.v2,
  });
  addFormula(s, "L_KoLeo = -(1/n) Î£áµ¢ log(d_{n,i})\n\nd_{n,i} = min_{jâ‰ i} ||xáµ¢ - xâ±¼||\n\n(features chuáº©n hÃ³a L2)", 6.5, 1.7, 6.3, 1.8, C.v2);

  // Intuition
  s.addText("Trá»±c giÃ¡c:", {
    x: 6.5, y: 3.7, w: 6.3, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.black,
  });
  s.addText("â€¢ Tá»« Kozachenko-Leonenko entropy estimator\nâ€¢ Tá»‘i Ä‘a hÃ³a khoáº£ng cÃ¡ch Ä‘áº¿n nearest neighbor\nâ€¢ â†’ Embeddings tráº£i Ä‘á»u trÃªn hypersphere\nâ€¢ Ãp dá»¥ng weight 0.1, chá»‰ CLS tokens", {
    x: 6.5, y: 4.1, w: 6.3, h: 1.5,
    fontFace: FONT, fontSize: 16, color: C.gray,
  });

  // Ablation
  s.addText("Táº¡i Sao KoLeo Quan Trá»ng:", {
    x: M, y: 4.6, w: 5.5, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.accent,
  });

  addTable(s,
    ["Cáº¥u hÃ¬nh", "ImageNet", "Retrieval"],
    [
      ["Model Ä‘áº§y Ä‘á»§", "85.8%", "63.9%"],
      ["KhÃ´ng KoLeo", "85.3%", "55.6% (-8.3%)"],
    ],
    M, 5.0, 5.5
  );

  addProgress(s, 16);
  s.addNotes(`KoLeo ngÄƒn embeddings cluster quÃ¡ cháº·t. Formula maximize log cá»§a min distance Ä‘áº¿n nearest neighbor - Ä‘áº©y má»—i embedding ra xa neighbor gáº§n nháº¥t. TÃªn tá»« Kozachenko-Leonenko entropy estimator. Ablation striking: bá» KoLeo chá»‰ hurt ImageNet nháº¹ (-0.5%), nhÆ°ng destroy retrieval (-8.3%). Classification chá»‰ cáº§n linearly separable. Retrieval cáº§n preserve fine-grained distances. Applied vá»›i weight 0.1 trÃªn CLS tokens.`);
})();

// SLIDE 17: Three Losses
(() => {
  const s = pres.addSlide();
  s.background = { color: C.bg };

  addTitle(s, "Ba Losses Káº¿t Há»£p", C.v2);

  // Architecture placeholder
  addPlaceholder(s, M, 1.3, 6, 3.5, "ViT â†’ CLS (DINO) + Patches (iBOT) + KoLeo", C.v2);

  // Total loss
  addFormula(s, "L_total = L_DINO + L_iBOT + 0.1 Ã— L_KoLeo", 7, 1.3, 5.8, 0.8, C.v2);

  // What each provides
  s.addText("Má»—i Loss Cung Cáº¥p GÃ¬:", {
    x: 7, y: 2.3, w: 5.8, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.black,
  });

  addTable(s,
    ["Loss", "Target", "Quan trá»ng cho"],
    [
      ["L_DINO", "CLS token", "Classification, retrieval"],
      ["L_iBOT", "Masked patches", "Segmentation, depth"],
      ["L_KoLeo", "Batch diversity", "Äá»™ chÃ­nh xÃ¡c retrieval"],
    ],
    7, 2.7, 5.8
  );

  // Ablation summary
  s.addText("TÃ³m Táº¯t Ablation:", {
    x: M, y: 5.0, w: CW, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.accent,
  });

  addTable(s,
    ["Bá» Ä‘i", "ImageNet", "ADE20k mIoU", "Retrieval"],
    [
      ["Model Ä‘áº§y Ä‘á»§", "85.8%", "47.1", "63.9%"],
      ["- KoLeo", "85.3%", "47.2", "55.6% (-8.3)"],
      ["- iBOT", "85.3%", "44.2 (-2.9)", "64.3%"],
    ],
    M, 5.4, CW * 0.8
  );

  addProgress(s, 17);
  s.addNotes(`Ba losses work together, má»—i cÃ¡i handle má»™t aspect khÃ¡c. DINO há»c global semantics tá»« CLS token - tá»‘t cho classification. iBOT há»c local understanding tá»« patches - essential cho dense tasks. KoLeo Ä‘áº£m báº£o diversity - critical cho retrieval. Ablation chá»©ng minh má»—i cÃ¡i necessary: Bá» KoLeo â†’ retrieval drop 8%. Bá» iBOT â†’ segmentation drop 3 mIoU. Not small effects.`);
})();

// SLIDE 18: DINOv2 Results
(() => {
  const s = pres.addSlide();
  s.background = { color: C.bg };

  addTitle(s, "Káº¿t Quáº£ DINOv2", C.v2);

  // Results table
  addTable(s,
    ["Benchmark", "DINOv2", "Tá»‘t nháº¥t trÆ°á»›c", "Task"],
    [
      ["ImageNet", "86.5%", "82.3% (iBOT)", "Classification"],
      ["ADE20k", "49.0 mIoU", "44.6 (iBOT)", "Segmentation"],
      ["Oxford-M", "64.6%", "39.0% (iBOT)", "Retrieval"],
      ["NYUd", "0.279 RMSE", "0.358 (iBOT)", "Depth"],
    ],
    M, 1.3, CW * 0.75
  );

  // Foundation Model achieved
  s.addShape(pres.shapes.RECTANGLE, {
    x: M, y: 3.8, w: CW, h: 1,
    fill: { color: "FFF3E0" },
    line: { color: C.v2, pt: 2 },
  });
  s.addText("Foundation Model Äáº¡t ÄÆ°á»£c:\n1 backbone (frozen) + simple linear head â†’ SOTA trÃªn nhiá»u tasks", {
    x: M + 0.2, y: 3.9, w: CW - 0.4, h: 0.9,
    fontFace: FONT, fontSize: 20, bold: true, color: C.v2, valign: "middle",
  });

  // Comparison with text-supervised
  s.addText("So SÃ¡nh vá»›i Text-Supervised:", {
    x: M, y: 5.1, w: CW, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.black,
  });

  addTable(s,
    ["Model", "ImageNet", "ADE20k", "DÃ¹ng Text?"],
    [
      ["OpenCLIP ViT-G", "86.2%", "46.0", "CÃ³ (LAION-2B)"],
      ["DINOv2 ViT-g", "86.5%", "49.0", "KHÃ”NG"],
    ],
    M, 5.5, CW * 0.7
  );

  addProgress(s, 18);
  s.addNotes(`DINOv2 achieves Foundation Model status. Má»™t frozen backbone, simple linear heads, state-of-the-art across classification, segmentation, retrieval, depth. 86.5% ImageNet vá»›i frozen features. Impressive nháº¥t: DINOv2 beats OpenCLIP vÃ  EVA-CLIP which use billions of image-text pairs. DINOv2 khÃ´ng dÃ¹ng text supervision. Pure visual self-supervision with right losses and data curation matches text-supervised methods.`);
})();

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ACT 4: EVOLUTION TO v3 (Slides 19-22)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// SLIDE 19: 7B Challenge
(() => {
  const s = pres.addSlide();
  s.background = { color: C.bg };

  addTitle(s, "ThÃ¡ch Thá»©c 7B - Dense Features Suy Giáº£m", C.v3);

  // Graph placeholder
  addPlaceholder(s, M, 1.3, 7, 3.5, "Äá»“ thá»‹ training: ImageNet tÄƒng, ADE20k Ä‘á»‰nh á»Ÿ 200k rá»“i GIáº¢M", C.v3);

  // The problem
  s.addText("Váº¥n Äá» (KHÃ”NG pháº£i divergence!):", {
    x: 8, y: 1.3, w: 4.8, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.accent,
  });

  addBullets(s, [
    "Classification tiáº¿p tá»¥c cáº£i thiá»‡n",
    "Segmentation Ä‘á»‰nh á»Ÿ ~200k",
    "Rá»“i GIáº¢M trong quÃ¡ trÃ¬nh training!",
    "Patches \"collapse\" vá» CLS",
  ], 8, 1.7, 4.8, 2.5, 16);

  // Root cause
  s.addText("NguyÃªn NhÃ¢n Gá»‘c:", {
    x: M, y: 5.0, w: CW, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.v3,
  });
  s.addText("â€¢ CLS token vÃ  patch outputs trá»Ÿ nÃªn quÃ¡ giá»‘ng nhau\nâ€¢ Patches máº¥t tÃ­nh Ä‘áº·c trÆ°ng khÃ´ng gian cá»¥c bá»™\nâ€¢ DINO global loss Ã¡p Ä‘áº£o iBOT local loss", {
    x: M, y: 5.4, w: CW, h: 1.2,
    fontFace: FONT, fontSize: 18, color: C.gray,
  });

  addProgress(s, 19);
  s.addNotes(`Scaling lÃªn 7B reveals váº¥n Ä‘á» má»›i. KhÃ´ng pháº£i training divergence - loss khÃ´ng explode. Thay vÃ o Ä‘Ã³, dense feature quality degrades. Classification keeps improving, nhÆ°ng segmentation peaks around 200k iterations rá»“i declines. Cause: CLS token vÃ  patch outputs become quÃ¡ similar. Patches "collapse" toward global summary, máº¥t local distinctiveness. DINO global loss dominates over iBOT local loss.`);
})();

// SLIDE 20: Gram Anchoring
(() => {
  const s = pres.addSlide();
  s.background = { color: C.bg };

  addTitle(s, "Gram Anchoring - CÃ´ng Thá»©c Äáº§y Äá»§", C.v3);

  // Gram matrix definition
  s.addText("Äá»‹nh NghÄ©a Ma Tráº­n Gram:", {
    x: M, y: 1.2, w: 6, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.v3,
  });
  addFormula(s, "G = X Â· X^T    (ma tráº­n P Ã— P)\n\nG[i,j] = cosine similarity\n        giá»¯a patch i vÃ  j", M, 1.6, 6, 1.6, C.v3);

  // Loss formula
  s.addText("Gram Anchoring Loss:", {
    x: M, y: 3.5, w: 6, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.v3,
  });
  addFormula(s, "L_Gram = ||X_S Â· X_S^T - X_G Â· X_G^T||Â²_F\n\nX_S = Student features (chuáº©n hÃ³a L2)\nX_G = Gram Teacher (checkpoint sá»›m)", M, 3.9, 6.5, 1.5, C.v3);

  // Key insight
  s.addShape(pres.shapes.RECTANGLE, {
    x: 7.5, y: 1.2, w: 5.3, h: 2.5,
    fill: { color: "E8F5E9" },
    line: { color: C.v3, pt: 2 },
  });
  s.addText("Insight Quan Trá»ng:", {
    x: 7.7, y: 1.3, w: 5, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.v3,
  });
  s.addText("RÃ ng buá»™c Cáº¤U TRÃšC TÆ¯Æ NG Tá»°, khÃ´ng pháº£i giÃ¡ trá»‹ features cá»¥ thá»ƒ.\n\nFeatures cÃ³ thá»ƒ rotate/scale/shift - chá»‰ cáº§n giá»¯ hÃ¬nh há»c tÆ°Æ¡ng Ä‘á»‘i!\n\nGram Teacher: checkpoint tá»« 100k-200k (khi dense features cÃ²n tá»‘t)", {
    x: 7.7, y: 1.7, w: 5, h: 2,
    fontFace: FONT, fontSize: 15, color: C.black,
  });

  // Refinement loss
  s.addText("Refinement Loss:", {
    x: 7.5, y: 4, w: 5.3, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.black,
  });
  addFormula(s, "L_Ref = L_DINO + L_iBOT + L_KoLeo\n       + 2 Ã— L_Gram", 7.5, 4.4, 5.3, 1, C.v3);

  // Effect
  s.addText("Hiá»‡u quáº£: Cáº£i thiá»‡n trong vÃ²ng 10k iterations!", {
    x: M, y: 5.8, w: CW, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.v3,
  });

  addProgress(s, 20);
  s.addNotes(`Gram Anchoring elegant. Gram matrix G = XÂ·X^T encode pairwise cosine similarities giá»¯a patches. G[i,j] cho biáº¿t patch i giá»‘ng patch j nhÆ° tháº¿ nÃ o. Loss minimize Frobenius norm giá»¯a Student's Gram matrix vÃ  Gram Teacher's. Preserve similarity structure. Key insight: Ä‘Ã¢y lÃ  SOFT constraint. Features cÃ³ thá»ƒ rotate, scale, shift - chá»‰ cáº§n preserve relative similarities. Gram Teacher tá»« early checkpoint (100k-200k) khi dense features cÃ²n good.`);
})();

// SLIDE 21: Text Alignment
(() => {
  const s = pres.addSlide();
  s.background = { color: C.bg };

  addTitle(s, "CÄƒn Chá»‰nh Text - Training TÃ¡ch Rá»i", C.v3);

  // Comparison placeholder
  addPlaceholder(s, M, 1.3, 6, 3, "CLIP (chung) vs DINOv3 (Giai Ä‘oáº¡n 1: SSL, Giai Ä‘oáº¡n 2: Frozen + Text)", C.v3);

  // Comparison table
  s.addText("CLIP vs DINOv3:", {
    x: 7, y: 1.3, w: 5.8, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.black,
  });

  addTable(s,
    ["KhÃ­a cáº¡nh", "CLIP", "DINOv3"],
    [
      ["Vision encoder", "Train chung", "FROZEN"],
      ["ÄÆ°á»£c train", "Cáº£ 2 encoders", "Text + 2 layers"],
      ["Features dÃ¹ng", "Chá»‰ CLS", "CLS + patches"],
      ["Kháº£ nÄƒng dense", "KÃ©m", "Xuáº¥t sáº¯c"],
    ],
    7, 1.7, 5.8
  );

  // Results
  s.addText("Káº¿t quáº£ (ADE20k segmentation):", {
    x: M, y: 4.8, w: CW, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.v3,
  });

  addTable(s,
    ["Model", "ADE20k mIoU"],
    [
      ["CLIP ViT-L", "6.0"],
      ["EVA-02-CLIP", "10.9"],
      ["DINOv3", "24.7 (tá»‘t hÆ¡n 4Ã—!)"],
    ],
    M, 5.2, 5
  );

  addProgress(s, 21);
  s.addNotes(`DINOv3 cÃ³ thá»ƒ align vá»›i text trong khi preserve dense capabilities. KhÃ¡c vá»›i CLIP train vision vÃ  text jointly (degrade spatial features), DINOv3 dÃ¹ng decoupled training. Phase 1: Train SSL backbone (1M iterations, khÃ´ng text). Phase 2: Freeze vision backbone, thÃªm 2 transformer layers, train text encoder tá»« scratch. Key enhancement: dÃ¹ng cáº£ CLS token VÃ€ mean-pooled patches cho alignment. Result: 24.7 mIoU vs CLIP's 6.0 - 4Ã— improvement.`);
})();

// SLIDE 22: DINOv3 Results
(() => {
  const s = pres.addSlide();
  s.background = { color: C.bg };

  addTitle(s, "Káº¿t Quáº£ DINOv3 - SOTA Má»i NÆ¡i", C.v3);

  // Results table
  addTable(s,
    ["Benchmark", "DINOv2-g", "DINOv3-7B", "Î”"],
    [
      ["ImageNet", "87.3%", "88.4%", "+1.1%"],
      ["ObjectNet", "66.0%", "79.0%", "+13%"],
      ["ADE20k", "49.5 mIoU", "55.9 mIoU", "+6.4"],
      ["COCO det", "~60 mAP", "66.1 mAP", "+6"],
      ["DAVIS", "76.6 J&F", "83.3 J&F", "+6.7"],
    ],
    M, 1.3, CW * 0.7
  );

  // Historic achievements
  s.addShape(pres.shapes.RECTANGLE, {
    x: M, y: 4.0, w: CW, h: 1.2,
    fill: { color: "E8F5E9" },
    line: { color: C.v3, pt: 2 },
  });
  s.addText("ThÃ nh Tá»±u Lá»‹ch Sá»­:", {
    x: M + 0.2, y: 4.1, w: CW - 0.4, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.v3,
  });
  s.addText("â€¢ SSL Ä‘áº§u tiÃªn ngang báº±ng weakly-supervised trÃªn ImageNet\nâ€¢ SOTA trÃªn COCO detection vá»›i backbone FROZEN (chá»‰ 100M decoder trainable)\nâ€¢ SOTA trÃªn ADE20k vá»›i frozen backbone (ngang models finetuned)", {
    x: M + 0.2, y: 4.5, w: CW - 0.4, h: 0.7,
    fontFace: FONT, fontSize: 16, color: C.black,
  });

  // Architecture & Training
  s.addText("Kiáº¿n trÃºc: ViT-7B (6.7B params), Axial RoPE, SwiGLU, 256k prototypes", {
    x: M, y: 5.5, w: CW, h: 0.4,
    fontFace: FONT, fontSize: 14, color: C.medGray,
  });
  s.addText("Training: 256 H100 GPUs, 61k GPU hours, ~18 táº¥n COâ‚‚", {
    x: M, y: 5.9, w: CW, h: 0.4,
    fontFace: FONT, fontSize: 14, color: C.medGray,
  });

  addProgress(s, 22);
  s.addNotes(`DINOv3 achieves SOTA everywhere vá»›i frozen backbone. 88.4% ImageNet - first SSL at weakly-supervised parity. 66.1 mAP trÃªn COCO detection - matching finetuned models vá»›i just 100M parameter decoder. 55.9 mIoU trÃªn ADE20k - 6 points above DINOv2. Dense task improvements Ä‘áº·c biá»‡t notable: +13% ObjectNet, +6.4 mIoU segmentation, +6.7 video tracking. Gram Anchoring solved dense feature degradation problem.`);
})();

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ACT 5: SYNTHESIS (Slides 23-24)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// SLIDE 23: Evolution Timeline
(() => {
  const s = pres.addSlide();
  s.background = { color: C.bg };

  addTitle(s, "DÃ²ng Thá»i Gian Tiáº¿n HÃ³a", C.success);

  // Timeline visual - using shapes
  const timelineY = 2.0;
  const startX = 1.5;
  const spacing = 4;

  // Timeline line
  s.addShape(pres.shapes.LINE, {
    x: startX, y: timelineY + 0.8,
    w: 10.5, h: 0,
    line: { color: C.lightGray, width: 3 },
  });

  // Version boxes
  const versions = [
    { year: "2021", name: "DINOv1", acc: "80.1%", color: C.v1, problem: "Há»c khÃ´ng cáº§n nhÃ£n", solution: "EMA + Centering + Sharpening" },
    { year: "2023", name: "DINOv2", acc: "86.5%", color: C.v2, problem: "Dense tasks yáº¿u", solution: "iBOT + KoLeo + Data curation" },
    { year: "2025", name: "DINOv3", acc: "88.4%", color: C.v3, problem: "Scale gÃ¢y suy giáº£m", solution: "Gram Anchoring + scale 7B" },
  ];

  versions.forEach((v, i) => {
    const x = startX + i * spacing;

    // Year
    s.addText(v.year, {
      x, y: timelineY - 0.3, w: 1.5, h: 0.4,
      fontFace: FONT, fontSize: 14, color: C.medGray, align: "center",
    });

    // Circle marker
    s.addShape(pres.shapes.OVAL, {
      x: x + 0.5, y: timelineY + 0.6, w: 0.4, h: 0.4,
      fill: { color: v.color },
    });

    // Box
    s.addShape(pres.shapes.RECTANGLE, {
      x, y: timelineY + 1.2, w: 3.5, h: 2.8,
      fill: { color: C.bg },
      line: { color: v.color, pt: 2 },
    });

    // Name and accuracy
    s.addText(v.name, {
      x: x + 0.1, y: timelineY + 1.3, w: 3.3, h: 0.4,
      fontFace: FONT, fontSize: 18, bold: true, color: v.color,
    });
    s.addText(v.acc, {
      x: x + 0.1, y: timelineY + 1.7, w: 3.3, h: 0.3,
      fontFace: FONT, fontSize: 14, color: C.medGray,
    });

    // Problem
    s.addText("Váº¥n Ä‘á»:", {
      x: x + 0.1, y: timelineY + 2.1, w: 3.3, h: 0.3,
      fontFace: FONT, fontSize: 12, bold: true, color: C.accent,
    });
    s.addText(v.problem, {
      x: x + 0.1, y: timelineY + 2.4, w: 3.3, h: 0.5,
      fontFace: FONT, fontSize: 12, color: C.black,
    });

    // Solution
    s.addText("Giáº£i phÃ¡p:", {
      x: x + 0.1, y: timelineY + 2.9, w: 3.3, h: 0.3,
      fontFace: FONT, fontSize: 12, bold: true, color: C.success,
    });
    s.addText(v.solution, {
      x: x + 0.1, y: timelineY + 3.2, w: 3.3, h: 0.5,
      fontFace: FONT, fontSize: 12, color: C.black,
    });
  });

  // Pattern
  s.addText("Máº«u hÃ¬nh: XÃ¡c Ä‘á»‹nh váº¥n Ä‘á» â†’ Giáº£i quyáº¿t â†’ TÃ¬m váº¥n Ä‘á» má»›i â†’ Láº·p láº¡i", {
    x: M, y: 6.0, w: CW, h: 0.4,
    fontFace: FONT, fontSize: 18, italic: true, color: C.gray, align: "center",
  });

  addProgress(s, 23);
  s.addNotes(`Timeline thá»ƒ hiá»‡n evolution rÃµ rÃ ng. Má»—i version giáº£i quyáº¿t háº¡n cháº¿ cá»§a version trÆ°á»›c. v1: lÃ m sao SSL work? v2: lÃ m sao cho dense tasks? v3: lÃ m sao scale lÃªn 7B? Pattern nÃ y cho tháº¥y research process: identify problem â†’ solve â†’ find new problem â†’ repeat.`);
})();

// SLIDE 24: Key Takeaways
(() => {
  const s = pres.addSlide();
  s.background = { color: C.bg };

  addTitle(s, "BÃ i Há»c ChÃ­nh + TÃ i Liá»‡u Tham Kháº£o", C.success);

  // 5 Lessons
  s.addText("5 BÃ i Há»c Tá»« DINO:", {
    x: M, y: 1.2, w: 7, h: 0.4,
    fontFace: FONT, fontSize: 20, bold: true, color: C.success,
  });

  addTable(s,
    ["#", "BÃ i há»c", "Báº±ng chá»©ng"],
    [
      ["1", "SSL cÃ³ thá»ƒ vÆ°á»£t Supervised", "88.4% vs 85.7%"],
      ["2", "NgÄƒn collapse lÃ  Cá»T Yáº¾U", "EMA + Centering + Sharpening"],
      ["3", "Cháº¥t lÆ°á»£ng > Sá»‘ lÆ°á»£ng data", "142M curated > 1.2B raw"],
      ["4", "Dense cáº§n patch-level learning", "iBOT: -2.9 mIoU náº¿u bá»"],
      ["5", "Scale cáº§n tricks á»•n Ä‘á»‹nh", "Gram Anchoring cho 7B"],
    ],
    M, 1.6, 7.5
  );

  // Key formulas
  s.addText("CÃ´ng Thá»©c ChÃ­nh:", {
    x: 8.5, y: 1.2, w: 4.3, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.black,
  });
  s.addText(`EMA:      Î¸â‚œ â† Î»Î¸â‚œ + (1-Î»)Î¸â‚›
Center:   c â† mc + (1-m)Â·mean
Loss:     L = -Î£ Pâ‚œÂ·log(Pâ‚›)
KoLeo:    L = -Î£ log(min dist)
Gram:     L = ||G_s - G_t||Â²`, {
    x: 8.5, y: 1.6, w: 4.3, h: 2,
    fontFace: FONT_MONO, fontSize: 12, color: C.gray,
  });

  // Papers
  s.addText("BÃ i bÃ¡o:", {
    x: M, y: 4.8, w: CW, h: 0.4,
    fontFace: FONT, fontSize: 18, bold: true, color: C.black,
  });
  s.addText(`â€¢ DINOv1: Caron et al., "Emerging Properties in Self-Supervised Vision Transformers", ICCV 2021
â€¢ DINOv2: Oquab et al., "DINOv2: Learning Robust Visual Features without Supervision", TMLR 2024
â€¢ DINOv3: Darcet et al., arXiv 2025`, {
    x: M, y: 5.2, w: CW, h: 1,
    fontFace: FONT, fontSize: 14, color: C.gray,
  });

  // Code
  s.addText("MÃ£ nguá»“n: github.com/facebookresearch/dinov2", {
    x: M, y: 6.2, w: CW, h: 0.4,
    fontFace: FONT, fontSize: 16, color: C.v1,
  });

  addProgress(s, 24);
  s.addNotes(`5 bÃ i há»c tá»« DINO: (1) SSL cÃ³ thá»ƒ vÆ°á»£t supervised. (2) Collapse prevention lÃ  critical - khÃ´ng cÃ³ EMA/Centering thÃ¬ khÃ´ng work. (3) Data quality > quantity. (4) Dense tasks cáº§n iBOT Ä‘á»ƒ hiá»ƒu local. (5) Scale lá»›n cáº§n stability tricks. DINO giá» lÃ  foundation model cho nhiá»u á»©ng dá»¥ng. Key insight: khÃ´ng cáº§n labels, cáº§n Ä‘Ãºng learning signal.`);
})();

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Save Presentation
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
pres.writeFile({ fileName: "DINO_Seminar_v6.8.pptx" })
  .then(() => console.log("âœ“ Created: DINO_Seminar_v6.8.pptx (24 slides, 30 min)"))
  .catch(err => console.error("Error:", err));
